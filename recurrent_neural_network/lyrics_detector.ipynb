{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyrics detector Challenge\n",
    "\n",
    "The goal for this challenge is to leverage your knowledge of Deep Learning to design and train a lyrics classifier. For a given verse $X$, our model should learn to predict the artist $y$. The dataset consists of lyrics scrapped from the Genius website.\n",
    "\n",
    "### Objectives:\n",
    "- Text preprocessing\n",
    "- Text embedding\n",
    "- Train a RNN to detect the artist behind a set of lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.205260Z",
     "start_time": "2021-06-25T17:22:11.396250Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning\n",
    "\n",
    "Our dataset contains around 4,000 verses of lyrics from different artists: Drake, Ed Sheeran and Kanye West (the verses are given in this order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.654079Z",
     "start_time": "2021-06-25T17:22:16.207433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>verse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Ayy, woah Ayy, ayy Yeah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I can't just be with you and only you Yeah, I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Well, summer, all I did was rest, okay? And Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drake</td>\n",
       "      <td>I'm makin' a change today The liquor been taki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Dame was like, \"Yo you got a deal with Capitol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Then one day I just went ahead and played it, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>\"I ain't gonna front, it's kinda hot.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Like they still weren't looking at me like a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>Kanye West</td>\n",
       "      <td>\"You gotta be under an umbrella, you'll get ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3975 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist                                              verse\n",
       "0          Drake                            Ayy, woah Ayy, ayy Yeah\n",
       "1          Drake  I'm makin' a change today The liquor been taki...\n",
       "2          Drake  I can't just be with you and only you Yeah, I ...\n",
       "3          Drake  Well, summer, all I did was rest, okay? And Ne...\n",
       "4          Drake  I'm makin' a change today The liquor been taki...\n",
       "...          ...                                                ...\n",
       "3970  Kanye West  Dame was like, \"Yo you got a deal with Capitol...\n",
       "3971  Kanye West  Then one day I just went ahead and played it, ...\n",
       "3972  Kanye West             \"I ain't gonna front, it's kinda hot.\"\n",
       "3973  Kanye West  Like they still weren't looking at me like a r...\n",
       "3974  Kanye West  \"You gotta be under an umbrella, you'll get ra...\n",
       "\n",
       "[3975 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/certification_france_2021_q2/verses.csv\")\n",
    "\n",
    "data = raw_data.copy() # From now on, update `data` as you see fit and don't touch raw_data\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Have a look at the verse index 18th**. \n",
    "- What do you observe?\n",
    "- Clean verses from non standard characters using [`unidecode.unidecode()`](https://pypi.org/project/Unidecode/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.663663Z",
     "start_time": "2021-06-25T17:22:16.658103Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "df=data.applymap(unidecode)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Check if some verses are duplicated.** \n",
    "- It can be frequent in music lyrics.\n",
    "- If so, remove them to avoid data leaks between train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated()]\n",
    "data=df.drop_duplicates()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:16.861084Z",
     "start_time": "2021-06-25T17:22:16.854026Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult(\n",
    "    'data_loading',\n",
    "    shape=data.shape,\n",
    "    verses=data.verse[:50]\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Analysis (given to you)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ **We check the number of unique artist and the number of verses per artist**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.182432Z",
     "start_time": "2021-06-25T17:22:19.175936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Drake         1391\n",
       "Ed Sheeran     861\n",
       "Kanye West     779\n",
       "Name: artist, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.artist.value_counts()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ **For each artist, let's have a look at the top-10 most used words to see if they look similar?**\n",
    "\n",
    "We'll use Tensorflow's [`Tokenizer`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer)'s index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.191343Z",
     "start_time": "2021-06-25T17:22:19.184174Z"
    }
   },
   "outputs": [],
   "source": [
    "drake = data[data.artist =='Drake'].verse\n",
    "ed = data[data.artist =='Ed Sheeran'].verse\n",
    "kanye = data[data.artist =='Kanye West'].verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.438880Z",
     "start_time": "2021-06-25T17:22:19.193277Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer_drake = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer_ed = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer_kanye = tf.keras.preprocessing.text.Tokenizer()\n",
    "\n",
    "tokenizer_drake.fit_on_texts(drake)\n",
    "tokenizer_ed.fit_on_texts(ed)\n",
    "tokenizer_kanye.fit_on_texts(kanye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.457776Z",
     "start_time": "2021-06-25T17:22:19.441016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drake</th>\n",
       "      <th>Ed Sheeran</th>\n",
       "      <th>Kanye West</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>to</td>\n",
       "      <td>me</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>my</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>it</td>\n",
       "      <td>to</td>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>me</td>\n",
       "      <td>a</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i'm</td>\n",
       "      <td>in</td>\n",
       "      <td>me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>my</td>\n",
       "      <td>i'm</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Drake Ed Sheeran Kanye West\n",
       "1      i          i          i\n",
       "2    you        you        the\n",
       "3    the        the        you\n",
       "4    and        and        and\n",
       "5     to         me         to\n",
       "6      a         my          a\n",
       "7     it         to         my\n",
       "8     me          a         it\n",
       "9    i'm         in         me\n",
       "10    my        i'm         in"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data={\n",
    "    \n",
    "    \"Drake\": pd.Series(tokenizer_drake.index_word)[:10],\n",
    "    \"Ed Sheeran\": pd.Series(tokenizer_ed.index_word)[:10],\n",
    "    \"Kanye West\": pd.Series(tokenizer_kanye.index_word)[:10],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ **Let's quantify how much vocabulary do they have in common**\n",
    "\n",
    "- An artist **vocabulary** is the **set** of all unique used words\n",
    "- We compute the `ratio` of (i) the length of vocabulary they **share**, over (ii) the length of the **total** vocabulary of the dataset\n",
    "\n",
    "<details>\n",
    "    <summary>Hints</summary>\n",
    "\n",
    "We'll use Python [`set.intersection()`](https://www.programiz.com/python-programming/methods/set/intersection) and [`set.union()`](https://www.programiz.com/python-programming/methods/set/union)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.465228Z",
     "start_time": "2021-06-25T17:22:19.460132Z"
    }
   },
   "outputs": [],
   "source": [
    "drake_vocabulary = set(tokenizer_drake.index_word.values())\n",
    "\n",
    "ed_vocabulary = set(tokenizer_ed.index_word.values())\n",
    "kanye_vocabulary = set(tokenizer_kanye.index_word.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.474902Z",
     "start_time": "2021-06-25T17:22:19.467454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.28% of the artists' vocabulary is common\n"
     ]
    }
   ],
   "source": [
    "common_vocabulary = drake_vocabulary.intersection(ed_vocabulary).intersection(kanye_vocabulary)\n",
    "global_vocabulary = drake_vocabulary.union(ed_vocabulary).union(kanye_vocabulary)\n",
    "\n",
    "ratio = len(common_vocabulary)/len(global_vocabulary)\n",
    "\n",
    "print(f\"{ratio*100:.2f}% of the artists' vocabulary is common\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Word Embedding\n",
    "We now need to think about embedding our sentences into numbers. We will be using [`gensim.models.Word2Vec`](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec) to embed each word of the sentence and concatenate the embeddings of the words forming the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Transform the list of strings (verses) into a list of word sequences (a word sequence is a list of words contained in a string)**\n",
    "- Store these sequences of words in a new column `data[\"seq\"]` in your dataframe\n",
    "- You can use `tensorflow.keras.preprocessing.text.text_to_word_sequence` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.569442Z",
     "start_time": "2021-06-25T17:22:19.478291Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-d192432507f9>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"seq\"]=data[[\"verse\"]].applymap(text_to_word_sequence)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "#from gensim.models import Word2Vec\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "#text_to_word_sequence(data.loc[0,[\"verse\"]][0])\n",
    "data[\"seq\"]=data[[\"verse\"]].applymap(text_to_word_sequence)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Let's check if we can cap the length of each sequences without losing too much information**\n",
    "- Plot the distribution of sequences lengths using the [`seaborn.kdeplot`](https://seaborn.pydata.org/generated/seaborn.displot.html#seaborn-displot) function\n",
    "- Does it seem reasonable to limit ourself to 300 words per verse later on? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.783874Z",
     "start_time": "2021-06-25T17:22:19.572393Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-6189d7a12490>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"len\"]=data[[\"seq\"]].applymap(len)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yes it seams resonable because most of the sentences len< 300 in the data'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOLklEQVR4nO3df6xfd13H8efLFUYEwzpXm9o1dmijqSaMpRkl8Md0ul8YhwkhW4xryJL6x4hgSEynf0whJCNRkCW4WKUyDDInP1wzFmatJMQ/GOt0GfvB7AU216ZbC5tDJTFO3/7x/dztS+nPe2+/d73v5yP55nvO+3y+53zO556+7rnne77fpqqQJPXwI8vdAUnS7Bj6ktSIoS9JjRj6ktSIoS9Jjaxa7g6cyAUXXFAbN25c7m5I0lnlwQcf/E5VrTnWsld06G/cuJF9+/Ytdzck6ayS5KnjLfPyjiQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ18or+RO5ibdzxxWXZ7pO3vn1ZtitJJ+OZviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiOGviQ1ctLQT7IhyZeTPJbk0STvHfXzk+xJsn88rx71JLktyVySh5NcMrWubaP9/iTbztxuSZKO5VTO9F8E3l9Vm4GtwE1JNgM7gL1VtQnYO+YBrgY2jcd24HaY/JIAbgHeDFwK3DL/i0KSNBsnDf2qOlRV/zym/wN4HFgPXAvcMZrdAbxjTF8LfKomvgqcl2QdcCWwp6qeq6rngT3AVUu5M5KkEzuta/pJNgJvAu4H1lbVobHoGWDtmF4PPD31sgOjdry6JGlGTjn0k7wO+Bzwvqr63vSyqiqglqJDSbYn2Zdk35EjR5ZilZKk4ZRCP8mrmAT+p6vq86P87Lhsw3g+POoHgQ1TL79w1I5X/wFVtbOqtlTVljVr1pzOvkiSTuJU7t4J8Ang8ar6yNSi3cD8HTjbgLun6jeMu3i2Ai+My0D3AVckWT3ewL1i1CRJM3Iq/13iW4HfBL6e5KFR+z3gVuCuJDcCTwHvGsvuBa4B5oDvA+8GqKrnknwQeGC0+0BVPbcUOyFJOjUnDf2q+icgx1l8+THaF3DTcda1C9h1Oh2UJC0dP5ErSY0Y+pLUiKEvSY0Y+pLUiKEvSY0Y+pLUiKEvSY0Y+pLUiKEvSY0Y+pLUiKEvSY0Y+pLUiKEvSY0Y+pLUiKEvSY0Y+pLUiKEvSY0Y+pLUiKEvSY0Y+pLUiKEvSY0Y+pLUiKEvSY0Y+pLUiKEvSY0Y+pLUiKEvSY0Y+pLUiKEvSY0Y+pLUiKEvSY0Y+pLUiKEvSY0Y+pLUiKEvSY0Y+pLUiKEvSY0Y+pLUiKEvSY2cNPST7EpyOMkjU7U/SHIwyUPjcc3UspuTzCV5IsmVU/WrRm0uyY6l3xVJ0smcypn+J4GrjlH/aFVdPB73AiTZDFwH/Px4zZ8mOSfJOcDHgauBzcD1o60kaYZWnaxBVX0lycZTXN+1wJ1V9d/At5PMAZeOZXNV9S2AJHeOto+dfpclSQu1mGv670ny8Lj8s3rU1gNPT7U5MGrHq/+QJNuT7Euy78iRI4voniTpaAsN/duBnwYuBg4Bf7xUHaqqnVW1paq2rFmzZqlWK0niFC7vHEtVPTs/neTPgXvG7EFgw1TTC0eNE9QlSTOyoDP9JOumZn8dmL+zZzdwXZJzk1wEbAK+BjwAbEpyUZJXM3mzd/fCuy1JWoiTnukn+QxwGXBBkgPALcBlSS4GCngS+C2Aqno0yV1M3qB9Ebipqv53rOc9wH3AOcCuqnp0qXdGknRip3L3zvXHKH/iBO0/BHzoGPV7gXtPq3eSpCXlJ3IlqRFDX5IaMfQlqRFDX5IaMfQlqRFDX5IaMfQlqRFDX5IaMfQlqRFDX5IaMfQlqRFDX5IaMfQlqRFDX5IaMfQlqRFDX5IaMfQlqRFDX5IaMfQlqRFDX5IaMfQlqRFDX5IaMfQlqRFDX5IaMfQlqRFDX5IaMfQlqRFDX5IaMfQlqRFDX5IaMfQlqRFDX5IaMfQlqRFDX5IaMfQlqRFDX5IaMfQlqRFDX5IaMfQlqZGThn6SXUkOJ3lkqnZ+kj1J9o/n1aOeJLclmUvycJJLpl6zbbTfn2TbmdkdSdKJnMqZ/ieBq46q7QD2VtUmYO+YB7ga2DQe24HbYfJLArgFeDNwKXDL/C8KSdLsnDT0q+orwHNHla8F7hjTdwDvmKp/qia+CpyXZB1wJbCnqp6rqueBPfzwLxJJ0hm20Gv6a6vq0Jh+Blg7ptcDT0+1OzBqx6v/kCTbk+xLsu/IkSML7J4k6VgW/UZuVRVQS9CX+fXtrKotVbVlzZo1S7VaSRILD/1nx2UbxvPhUT8IbJhqd+GoHa8uSZqhhYb+bmD+DpxtwN1T9RvGXTxbgRfGZaD7gCuSrB5v4F4xapKkGVp1sgZJPgNcBlyQ5ACTu3BuBe5KciPwFPCu0fxe4BpgDvg+8G6AqnouyQeBB0a7D1TV0W8OS5LOsJOGflVdf5xFlx+jbQE3HWc9u4Bdp9U7SdKS8hO5ktSIoS9JjRj6ktSIoS9JjRj6ktSIoS9JjRj6ktSIoS9JjRj6ktSIoS9JjRj6ktSIoS9JjRj6ktSIoS9JjRj6ktSIoS9JjRj6ktSIoS9JjRj6ktSIoS9JjRj6ktSIoS9JjRj6ktSIoS9JjRj6ktSIoS9JjRj6ktSIoS9JjRj6ktSIoS9JjRj6ktSIoS9JjRj6ktSIoS9Jjaxa7g6sRBt3fHHZtv3krW9ftm1LeuXzTF+SGjH0JakRQ1+SGjH0JamRRYV+kieTfD3JQ0n2jdr5SfYk2T+eV496ktyWZC7Jw0kuWYodkCSduqU40//Fqrq4qraM+R3A3qraBOwd8wBXA5vGYztw+xJsW5J0Gs7E5Z1rgTvG9B3AO6bqn6qJrwLnJVl3BrYvSTqOxYZ+AX+f5MEk20dtbVUdGtPPAGvH9Hrg6anXHhi1H5Bke5J9SfYdOXJkkd2TJE1b7Iez3lZVB5P8BLAnyTemF1ZVJanTWWFV7QR2AmzZsuW0XitJOrFFnelX1cHxfBj4AnAp8Oz8ZZvxfHg0PwhsmHr5haMmSZqRBYd+ktcm+bH5aeAK4BFgN7BtNNsG3D2mdwM3jLt4tgIvTF0GkiTNwGIu76wFvpBkfj1/XVVfSvIAcFeSG4GngHeN9vcC1wBzwPeBdy9i25KkBVhw6FfVt4A3HqP+XeDyY9QLuGmh25MkLZ6fyJWkRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWpk1XJ3QEtr444vLst2n7z17cuyXUmnxzN9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE0JekRgx9SWrE797RkvA7f6Szg2f6ktSIoS9Jjcw89JNcleSJJHNJdsx6+5LU2UxDP8k5wMeBq4HNwPVJNs+yD5LU2azfyL0UmKuqbwEkuRO4Fnhsxv3QCrFcbyBrtpbzDfuVdpPCrEN/PfD01PwB4M3TDZJsB7aP2f9M8sQCt3UB8J0FvnalcSwmHIeJs24c8uEztupX7Fgscp9/6ngLXnG3bFbVTmDnYteTZF9VbVmCLp31HIsJx2HCcXhZx7GY9Ru5B4ENU/MXjpokaQZmHfoPAJuSXJTk1cB1wO4Z90GS2prp5Z2qejHJe4D7gHOAXVX16Bna3KIvEa0gjsWE4zDhOLys3Vikqpa7D5KkGfETuZLUiKEvSY2syNDv9FUPSTYk+XKSx5I8muS9o35+kj1J9o/n1aOeJLeNsXk4ySXLuwdLK8k5Sf4lyT1j/qIk94/9/ZtxAwFJzh3zc2P5xmXt+BJLcl6Szyb5RpLHk7yl4zGR5HfGv4tHknwmyWu6HhPzVlzoN/yqhxeB91fVZmArcNPY3x3A3qraBOwd8zAZl03jsR24ffZdPqPeCzw+Nf9h4KNV9TPA88CNo34j8Pyof3S0W0k+Bnypqn4OeCOTMWl1TCRZD/w2sKWqfoHJzSPX0feYmKiqFfUA3gLcNzV/M3Dzcvdrhvt/N/ArwBPAulFbBzwxpv8MuH6q/UvtzvYHk8997AV+CbgHCJNPW646+thgcgfZW8b0qtEuy70PSzQOrwe+ffT+dDsmePkbAM4fP+N7gCs7HhPTjxV3ps+xv+ph/TL1ZabGn6NvAu4H1lbVobHoGWDtmF7J4/MnwO8C/zfmfxz496p6ccxP7+tL4zCWvzDarwQXAUeAvxyXuv4iyWtpdkxU1UHgj4B/Aw4x+Rk/SM9j4iUrMfRbSvI64HPA+6rqe9PLanLqsqLvzU3yq8DhqnpwufvyCrAKuAS4vareBPwXL1/KAdocE6uZfKHjRcBPAq8FrlrWTr0CrMTQb/dVD0lexSTwP11Vnx/lZ5OsG8vXAYdHfaWOz1uBX0vyJHAnk0s8HwPOSzL/IcTpfX1pHMby1wPfnWWHz6ADwIGqun/Mf5bJL4Fux8QvA9+uqiNV9T/A55kcJx2PiZesxNBv9VUPSQJ8Ani8qj4ytWg3sG1Mb2NyrX++fsO4Y2Mr8MLUn/xnraq6uaourKqNTH7m/1hVvwF8GXjnaHb0OMyPzztH+xVx5ltVzwBPJ/nZUbqcydeXtzommFzW2ZrkR8e/k/lxaHdM/IDlflPhTDyAa4B/Bb4J/P5y9+cM7+vbmPyZ/jDw0Hhcw+Ra5F5gP/APwPmjfZjc3fRN4OtM7mxY9v1Y4jG5DLhnTL8B+BowB/wtcO6ov2bMz43lb1jufi/xGFwM7BvHxd8BqzseE8AfAt8AHgH+Cji36zEx//BrGCSpkZV4eUeSdByGviQ1YuhLUiOGviQ1YuhLUiOGviQ1YuhLUiP/D+uFJ81TLUVEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "import matplotlib.pyplot as plt\n",
    "data[\"len\"]=data[[\"seq\"]].applymap(len)\n",
    "plt.hist(data.len)\n",
    "\n",
    "\n",
    "\"\"\"yes it seams resonable because most of the sentences len< 300 in the data\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Keep only the first `300` words of each sequences to reduce the useless long tail of long verses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:19.797635Z",
     "start_time": "2021-06-25T17:22:19.786221Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def f(x):\n",
    "    return x[:300]\n",
    "dff=data.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dff[\"seq\"]=data[[\"seq\"]].applymap(f)\n",
    "dff[\"len\"]=dff[[\"seq\"]].applymap(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.len.max()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Train a `gensim.models.Word2Vec` model on your dataset** \n",
    "- You want to embed each word into vectors of dimension `100`\n",
    "- No words should be excluded\n",
    "- Give Word2Vec at least 50 epochs to be sure it converges\n",
    "- Store these lists of vectors in a new column `data[\"embed\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:26.587185Z",
     "start_time": "2021-06-25T17:22:19.799947Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "X=dff[\"seq\"].tolist()\n",
    "word2vec = Word2Vec(sentences=X,vector_size=100,epochs=50)\n",
    "\n",
    "\n",
    "\n",
    "def embed_sentence(word2vec, sentence):\n",
    "    ls=[]\n",
    "    for word in sentence:\n",
    "        \n",
    "        if word in word2vec.wv.key_to_index.keys():\n",
    "            \n",
    "            ls.append(word2vec.wv[word])\n",
    "            \n",
    "            \n",
    "    return np.array(ls)\n",
    "\n",
    "def embedding(word2vec, sentences):\n",
    "    ls=[]\n",
    "    for sentence in sentences:\n",
    "        ls.append(embed_sentence(word2vec, sentence))\n",
    "        return np.array(ls)\n",
    "\n",
    "# Embed the training and test sentences\n",
    "#data[\"embed\"] = \n",
    "\n",
    "XX=embedding(word2vec, dff[\"seq\"].tolist())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-58-c549e491c281>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"embed\"]=pd.Series([XX[i] for i in range(XX.shape[0])])\n"
     ]
    }
   ],
   "source": [
    "data[\"embed\"]=pd.Series([XX[i] for i in range(XX.shape[0])])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:27.636650Z",
     "start_time": "2021-06-25T17:22:27.634359Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check \n",
    "assert len(data['embed']) == len(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create (X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Create your numpy array `X` of shape (number_of_verses, 300, 100)**\n",
    "\n",
    "- 300 words per verse (pad verses shorter than 300 with zeros at the end) \n",
    "- each words being a vector of size 100\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/lewagon/data-images/master/DL/padding.png\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:28.272086Z",
     "start_time": "2021-06-25T17:22:27.638449Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.24772182, -0.12220649,  0.34941748, ..., -0.9122767 ,\n",
       "          1.4532892 ,  1.0880207 ],\n",
       "        [ 1.7620589 ,  1.8733112 ,  0.18248849, ...,  0.6533363 ,\n",
       "          0.5319215 ,  2.0717027 ],\n",
       "        [ 0.24772182, -0.12220649,  0.34941748, ..., -0.9122767 ,\n",
       "          1.4532892 ,  1.0880207 ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X=pad_sequences(XX, dtype='float32', padding='post', maxlen=300)\n",
    "X\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Create the numpy array `y` of shape `(n_verses, 3)` that contains the one-hot-encoded list of labels, for the RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:28.394015Z",
     "start_time": "2021-06-25T17:22:28.274638Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " ...]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "yy=data[\"artist\"].tolist()\n",
    "yy\n",
    "\n",
    "# y=set(yy)\n",
    "\n",
    "\n",
    "# theset=[[i for i in y]]\n",
    "\n",
    "\n",
    "\n",
    "# enc = OneHotEncoder(handle_unknown='ignore')\n",
    "# enc.fit(theset)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# yy=enc.transform([yy])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ We train/test split the dataset below for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:29.558686Z",
     "start_time": "2021-06-25T17:22:28.400774Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:29.803743Z",
     "start_time": "2021-06-25T17:22:29.563431Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult(\n",
    "    'data_preprocessing',\n",
    "    n_zeros = np.sum(X == 0),\n",
    "    X_shape = X.shape,\n",
    "    y_shape = y.shape,\n",
    ")\n",
    "\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Run this code below if you haven't managed to build your own (X,Y) training sets. This will load them as solution\n",
    "\n",
    "```python\n",
    "! wget \\\n",
    "'https://wagon-public-datasets.s3.amazonaws.com/certification_france_2021_q2/data_lyrics_solution.pickle'\n",
    "\n",
    "import pickle\n",
    "with open(\"data_lyrics_solution.pickle\", \"rb\") as file:\n",
    "    (X_train, y_train, X_test, y_test) = pickle.load(file)\n",
    "    \n",
    "! rm data_lyrics_solution.pickle\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **First, store your baseline accuracy to beat as `score_baseline`**\n",
    "- Consider predicting always the most frequent artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:22:33.555223Z",
     "start_time": "2021-06-25T17:22:33.547120Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Create a RNN architecture to predict the artists `y`  given verses `X`** :\n",
    "\n",
    "- Keep it simple: use only one LSTM layer and one *hidden* dense layer between the input and output layers\n",
    "- Don't forget to take care of fake \"zeros\" added during preprocessing\n",
    "- Store it into the `model` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:27:09.448283Z",
     "start_time": "2021-06-25T17:27:08.796094Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "preproc_numerical_baseline = make_pipeline(\n",
    "    SimpleImputer(),\n",
    "    MinMaxScaler())\n",
    "\n",
    "preproc_categorical_baseline = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "\n",
    "preproc_transformer = make_column_transformer(\n",
    "    (preproc_numerical_baseline, make_column_selector(dtype_include=[\"int64\", \"float64\"])),\n",
    "    (preproc_categorical_baseline, make_column_selector(dtype_include=['object','bool'])),\n",
    "    remainder=\"drop\")\n",
    "\n",
    "preproc_selector = SelectPercentile(\n",
    "    mutual_info_regression,\n",
    "    percentile=50, # keep only 50% of all features most influencing the target\n",
    ")\n",
    "\n",
    "preproc = make_pipeline(\n",
    "    preproc_transformer,\n",
    "    preproc_selector\n",
    ")\n",
    "pipe_baseline = make_pipeline(preproc, lasso())\n",
    "\n",
    "\n",
    "rmsle = make_scorer(mean_squared_log_error)\n",
    "\n",
    "score_baseline = cross_val_score(pipe_baseline, X, y, cv=5, scoring=rmsle).mean()\n",
    "\n",
    "# Predict y_pred_baseline\n",
    "pipe_baseline.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Train your `model` on the `(X_train, y_train)` training set**\n",
    "- Use an appropriate loss\n",
    "- Adapt the learning rate of your optimizer if convergence is too slow/fast\n",
    "- Make sure your model does not overfit with appropriate control techniques\n",
    "\n",
    "üí° You will not be judged by the computing power of your computer, you can reach decent performance in less than 3 minutes of training without GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:28:13.790957Z",
     "start_time": "2021-06-25T17:27:09.537171Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Plot the training and validation losses through training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:28:13.814449Z",
     "start_time": "2021-06-25T17:28:13.793297Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot below your train/val loss history\n",
    "# YOUR CODE HERE\n",
    "# YOUR CODE HERE\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Run also this code to save figure as jpg in path below (it's your job to ensure it works)\n",
    "fig = plt.gcf()\n",
    "plt.savefig(\"tests/history.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Save your accuracy on test set as `score_test`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:29:15.350717Z",
     "start_time": "2021-06-25T17:29:14.925473Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Send your results below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T17:25:11.216908Z",
     "start_time": "2021-06-25T17:25:11.208773Z"
    }
   },
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult(\n",
    "    \"network\",\n",
    "    loss = model.loss,\n",
    "    input_shape = list(model.input.shape),\n",
    "    layer_names = [layer.name for layer in model.layers],\n",
    "    final_activation = model.layers[-1].activation.__wrapped__._keras_api_names[0],\n",
    "    score_baseline = score_baseline,\n",
    "    score_test = score_test,\n",
    ")\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
